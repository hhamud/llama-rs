[package]
name = "llm"
version = "0.1.0-rc1"
license = { workspace = true }
repository = { workspace = true }
description = "A Rust ecosystem of libraries for running inference on large language models, inspired by llama.cpp."
edition = "2021"

[dependencies]
llm-base = { path = "../llm-base", version = "0.1.0-rc1" }
llm-llama = { path = "../models/llama", features = ["convert"], optional = true, version = "0.1.0-rc1" }
llm-gpt2 = { path = "../models/gpt2", optional = true, version = "0.1.0-rc1" }
llm-gptj = { path = "../models/gptj", optional = true, version = "0.1.0-rc1" }
llm-bloom = { path = "../models/bloom", optional = true, version = "0.1.0-rc1" }
llm-neox = { path = "../models/neox", optional = true, version = "0.1.0-rc1" }
llm-codegen = { path = "../models/codegen", optional = true, version = "0.1.0-rc1" }

[dev-dependencies]
rand = { workspace = true }

[features]
default = ["llama", "gpt2", "gptj", "bloom", "neox", "codegen"]
llama = ["dep:llm-llama"]
gpt2 = ["dep:llm-gpt2"]
gptj = ["dep:llm-gptj"]
bloom = ["dep:llm-bloom"]
neox = ["dep:llm-neox"]
codegen = ["dep:llm-codegen"]
